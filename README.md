# DIMEMEX 2025 Baselines

This repository presents the official baselines proposed for the **DIMEMEX 2025** task, which focuses on the detection of hate speech and inappropriate content in memes written in Mexican Spanish.

For more details about the task, please visit the official competition page:  
ðŸ‘‰ [https://codalab.lisn.upsaclay.fr/competitions/22012](https://codalab.lisn.upsaclay.fr/competitions/22012)

---

## Text and Image-based Baselines for Subtasks 1 and 2

The baselines described in this section were adapted for evaluation on the first two subtasks.

The **first baseline** relies exclusively on the text modality and involves fine-tuning the pre-trained [BETO model](https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased).

The **second baseline** focuses solely on the visual modality, fine-tuning the pre-trained [Vision Transformer (ViT) model](https://huggingface.co/docs/transformers/model_doc/vit).

The **third baseline** integrates both textual and visual modalities using an **early fusion** approach. Specifically, it concatenates the classification vectors generated by the BETO and ViT models before the final prediction layer.

All three baselines are implemented in the `deep_baselines.py` file, which requires three mandatory command-line arguments:

- `--architecture_mode`: defines the baseline architecture to be used. Available options are: `BETO`, `ViT`, and `EF` (early fusion).
- `--evaluation_type`: specifies the dataset partition used for evaluation. Acceptable values are: `test` and `validation`.
- `--task`: indicates the subtask to evaluate. Valid options are: `1` and `2`.

### ðŸ”§ Example Usage (on the test dataset)

```bash
python3 llm_baseline.py --evaluation_type test --architecture_mode BETO --task 1
python3 llm_baseline.py --evaluation_type test --architecture_mode ViT --task 1
python3 llm_baseline.py --evaluation_type test --architecture_mode EF --task 1
python3 llm_baseline.py --evaluation_type test --architecture_mode BETO --task 2
python3 llm_baseline.py --evaluation_type test --architecture_mode ViT --task 2
python3 llm_baseline.py --evaluation_type test --architecture_mode EF --task 2
```

## LLM Baseline (Subtask 3)

The baseline provided for subtask 3 is based on a **zero-shot in-context learning** approach. It uses the `meta-llama/Llama-3.2-11B-Vision-Instruct` model to classify memes into one of the following three categories:

- Hate Speech  
- Inappropriate Content  
- None

The model receives:
- The image of the meme,
- The extracted text via OCR, and
- An automatically generated description of the meme.

All three components are used as input to the model in order to make a classification decision.

### ðŸ”§ Evaluation Instructions

To run the model, use the `--evaluation_type` argument to specify the evaluation dataset. The available options are:

```bash
python3 llm_baseline.py --evaluation_type validation
python3 llm_baseline.py --evaluation_type test
```